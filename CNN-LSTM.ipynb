{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90032bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense, LSTM, Conv1D, Dropout, Bidirectional, Multiply, Flatten, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a0e864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置全局参数\n",
    "TIME_STEPS = 4\n",
    "MODEL_PATH = './model.h5'  \n",
    "\n",
    "# 函数：创造时间序列数据集\n",
    "def create_dataset_with_lookback_and_skip(dataset, look_back=TIME_STEPS):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(0, len(dataset) - look_back + 1, look_back):\n",
    "        a = dataset[i:(i + look_back), 1:]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back - 1, 0])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "# 注意力机制\n",
    "def attention_3d_block(inputs):\n",
    "    input_dim = int(K.int_shape(inputs)[2])\n",
    "    a = Dense(input_dim, activation='softmax')(inputs) \n",
    "    a_probs = Multiply()([inputs, a])\n",
    "    return a_probs\n",
    "\n",
    "# 创建带有注意力机制的BiLSTM模型\n",
    "def build_model(lstm_units, dropout, input_dims):\n",
    "    inputs = Input(shape=(TIME_STEPS, input_dims))\n",
    "    x = Conv1D(filters=64, kernel_size=4, strides=1, activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling1D(pool_size=1)(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    lstm_out = Bidirectional(LSTM(lstm_units, return_sequences=True))(x)\n",
    "    lstm_out = Dropout(dropout)(lstm_out)\n",
    "    attention_mul = attention_3d_block(lstm_out)\n",
    "    attention_mul = Flatten()(attention_mul)\n",
    "    output = Dense(1, activation='linear')(attention_mul)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# 贝叶斯超参数优化目标函数\n",
    "def train_and_evaluate_model(lstm_units, dropout, batch_size, epochs):\n",
    "    lstm_units = int(round(lstm_units))  # 确保 LSTM 单元数为整数\n",
    "    batch_size = int(round(batch_size / 2) * 2)  # 批量大小调整为偶数\n",
    "    epochs = int(round(epochs))  # 确保 epoch 数为整数\n",
    "    dropout = round(dropout, 1)  # 保留一位小数\n",
    "    K.clear_session()  # 清除当前会话，避免内存泄漏\n",
    "\n",
    "    # 构建模型\n",
    "    model = build_model(\n",
    "        lstm_units=lstm_units,\n",
    "        dropout=dropout,\n",
    "        input_dims=train_X.shape[2]  # 仅使用动态特征的输入维度\n",
    "    )\n",
    "\n",
    "    # 定义回调函数\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=8, mode='min')\n",
    "    model_checkpoint = ModelCheckpoint(MODEL_PATH.format(datetime.now().strftime('%Y%m%d_%H%M%S')),\n",
    "                                        save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "    # 模型训练\n",
    "    history = model.fit(\n",
    "        train_X,  # 使用训练集的动态特征\n",
    "        train_Y,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[early_stopping, model_checkpoint],\n",
    "        verbose=0\n",
    "    )\n",
    "    val_loss = min(history.history['val_loss'])  # 获取验证集的最小损失值\n",
    "    return -val_loss  # 贝叶斯优化需要最大化目标值，因此取负\n",
    "\n",
    "# 模型训练函数\n",
    "def train_model(train_X, train_Y):\n",
    "    model = build_model(INPUT_DIMS)\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "    \n",
    "    # 回调函数\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=40, mode='min')\n",
    "    model_checkpoint = ModelCheckpoint(MODEL_PATH.format(datetime.now().strftime('%Y%m%d_%H%M%S')),\n",
    "                                        save_best_only=True, monitor='val_loss', mode='min')\n",
    "    \n",
    "    # 模型训练\n",
    "    history = model.fit(\n",
    "        train_X, train_Y,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[early_stopping, model_checkpoint]\n",
    "    )\n",
    "    return model, history\n",
    "\n",
    "# 评估模型并计算 R² 和 RMSE\n",
    "def evaluate_model(model, X, Y, dataset_type='Test'):\n",
    "    results = model.predict(X).flatten()  # 确保输出为 1D\n",
    "    r2 = r2_score(Y, results)\n",
    "    rmse = np.sqrt(mean_squared_error(Y, results))\n",
    "    print(f'{dataset_type} R^2: {r2:.4f}, RMSE: {rmse:.4f}')\n",
    "    return results, r2, rmse\n",
    "\n",
    "# 数据归一化和反归一化\n",
    "def normalize_data(data):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "    return scaled_data, scaler\n",
    "\n",
    "def inverse_normalize(data, scaler):\n",
    "    return scaler.inverse_transform(data)\n",
    "\n",
    "# 绘制训练曲线\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    if 'mae' in history.history:\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['mae'], label='Train MAE')\n",
    "        plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "        plt.title('Model MAE')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('MAE')\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# 反归一化预测值和实际值\n",
    "def inverse_target_only(data, scaler):\n",
    "    # 仅反归一化目标列，假设目标列是第一个\n",
    "    dummy_data = np.zeros((len(data), scaler.scale_.shape[0]))\n",
    "    dummy_data[:, 0] = data.flatten()\n",
    "    return scaler.inverse_transform(dummy_data)[:, 0]\n",
    "def inverse_and_export_results(predictions, actuals, scaler, output_path):\n",
    "    # 反归一化\n",
    "    predictions_inverse = inverse_target_only(predictions, scaler)\n",
    "    actuals_inverse = inverse_target_only(actuals, scaler)\n",
    "    \n",
    "    # 创建 DataFrame 保存结果\n",
    "    results_df = pd.DataFrame({\n",
    "        'Predicted': predictions_inverse,\n",
    "        'Actual': actuals_inverse\n",
    "    })\n",
    "    \n",
    "    # 导出到 CSV 文件\n",
    "    results_df.to_csv(output_path, index=False)\n",
    "    print(f\"Results exported to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c74da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取本地的训练集和测试集数据\n",
    "train_data = pd.read_excel(r\"F:\\Data\\Study\\DataSet\\Project\\1.Linan\\M_data\\Prediction\\La_15-18_30m_Train.xlsx\")\n",
    "test_data = pd.read_excel(r\"F:\\Data\\Study\\DataSet\\Project\\1.Linan\\M_data\\Prediction\\La_15-18_30m_Test.xlsx\")\n",
    "train_df = train_data.drop(['FID','YSSZ','TIME'], axis=1)\n",
    "test_df = test_data.drop(['FID','YSSZ','TIME'], axis=1)\n",
    "\n",
    "# 使用随机森林计算特征重要性\n",
    "target_column = 'AGB'  # 假设目标变量为 'AGB'\n",
    "X_train = train_df.drop(columns=[target_column])\n",
    "y_train = train_df[target_column]\n",
    "\n",
    "X_test = test_df.drop(columns=[target_column])\n",
    "y_test = test_df[target_column]\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 提取特征重要性\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# 打印特征重要性\n",
    "print(\"Feature Importance from Random Forest:\")\n",
    "print(feature_importances)\n",
    "\n",
    "# 绘制特征重要性柱状图\n",
    "plt.figure(figsize=(9, 7))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importances)\n",
    "plt.title('Feature Importances from Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e1ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建特征重要性表格，并取前10个特征\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# === 4. 取前 10 个特征 ===\n",
    "top_features = feature_importances.head(10)\n",
    "\n",
    "print(\"Top 10 Important Features:\")\n",
    "print(top_features)\n",
    "\n",
    "# === 5. 绘图展示 ===\n",
    "plt.figure(figsize=(3, 2.5), dpi=200)\n",
    "ax = sns.barplot(x='Feature', y='Importance', data=top_features, color='teal')\n",
    "\n",
    "# 设置标题与坐标轴\n",
    "plt.title('Annual Module Feature Importance (Linan)', fontsize=7.5, fontweight='light')\n",
    "plt.xlabel('', fontsize=5.5)\n",
    "plt.ylabel('', fontsize=5.5)\n",
    "ax.tick_params(axis='x', labelsize=5.5, rotation=45)  # 旋转特征名，防止重叠\n",
    "ax.tick_params(axis='y', labelsize=5.5)\n",
    "\n",
    "# 网格线 + 布局\n",
    "ax.grid(True, linestyle='', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f2a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置特征重要性阈值，选择重要性高于阈值的特征\n",
    "top_k_features = 10  # 选择前n个特征\n",
    "selected_features = feature_importances['Feature'].iloc[:top_k_features].tolist()\n",
    "print(\"Selected features based on importance threshold:\", selected_features)\n",
    "\n",
    "# 根据随机森林选择的特征构建数据集\n",
    "if selected_features:\n",
    "    train_df = train_df[[target_column] + selected_features]\n",
    "    test_df = test_df[[target_column] + selected_features]\n",
    "else:\n",
    "    raise ValueError(\"No significant features selected.\")\n",
    "\n",
    "# 归一化训练集和测试集\n",
    "train_scaled, scaler = normalize_data(train_df.values)\n",
    "test_scaled = scaler.transform(test_df.values)  # 使用训练集的scaler对测试集进行归一化\n",
    "\n",
    "# 创建时间序列数据集\n",
    "train_X, train_Y = create_dataset_with_lookback_and_skip(train_scaled, TIME_STEPS)\n",
    "test_X, test_Y = create_dataset_with_lookback_and_skip(test_scaled, TIME_STEPS)\n",
    "\n",
    "# 打印数据集形状\n",
    "print(f'Train X shape: {train_X.shape}, Train Y shape: {train_Y.shape}')\n",
    "print(f'Test X shape: {test_X.shape}, Test Y shape: {test_Y.shape}')\n",
    "\n",
    "# 设置输入维度\n",
    "INPUT_DIMS = len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944be675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义参数搜索空间，并为 batch_size 设置合理步长\n",
    "pbounds = {\n",
    "    'lstm_units': (32, 96),\n",
    "    'dropout': (0.0, 0.0),\n",
    "    'batch_size': (32, 64),\n",
    "    'epochs': (50, 100)\n",
    "}\n",
    "\n",
    "# 定义开关变量\n",
    "use_bayesian_optimization = False  # 如果为 True，则使用贝叶斯优化；为 False 则使用自定义参数\n",
    "\n",
    "if use_bayesian_optimization:\n",
    "    # 执行贝叶斯优化\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=train_and_evaluate_model,\n",
    "        pbounds=pbounds,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    optimizer.maximize(init_points=4, n_iter=14)\n",
    "\n",
    "    # 获取最佳参数\n",
    "    best_params = optimizer.max['params']\n",
    "    best_params['batch_size'] = int(round(best_params['batch_size'] / 2) * 2)\n",
    "    best_params['epochs'] = int(round(best_params['epochs']))\n",
    "    best_params['lstm_units'] = int(round(best_params['lstm_units']))\n",
    "    best_params['dropout'] = round(best_params['dropout'], 1)\n",
    "\n",
    "    print(\"Best Parameters from Bayesian Optimization:\", best_params)\n",
    "else:\n",
    "    # 使用自定义参数\n",
    "    best_params = {\n",
    "        'lstm_units': 64,\n",
    "        'dropout': 0.0,\n",
    "        'batch_size': 64,\n",
    "        'epochs': 100\n",
    "    }\n",
    "    print(\"Using custom parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc74e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "final_model = build_model(\n",
    "    lstm_units=int(best_params['lstm_units']),\n",
    "    dropout=round(best_params['dropout'], 1),\n",
    "    input_dims=INPUT_DIMS\n",
    ")\n",
    "\n",
    "# 模型训练\n",
    "final_history = final_model.fit(\n",
    "    train_X, train_Y,\n",
    "    epochs=int(best_params['epochs']),\n",
    "    batch_size=int(best_params['batch_size']),\n",
    "    validation_split=0.1,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=40, mode='min')],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 训练集和测试集评估\n",
    "train_results, train_r2, train_rmse = evaluate_model(final_model, train_X, train_Y, dataset_type='Train')\n",
    "test_results, test_r2, test_rmse = evaluate_model(final_model, test_X, test_Y, dataset_type='Test')\n",
    "\n",
    "# 调用 plot_history 显示训练过程中的损失曲线\n",
    "plot_history(final_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab120a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型预测\n",
    "train_predictions = final_model.predict([train_X])\n",
    "test_predictions = final_model.predict([test_X])\n",
    "\n",
    "# 反归一化训练集的预测结果和实际值\n",
    "train_predictions_inverse = inverse_target_only(train_predictions, scaler)\n",
    "train_actuals_inverse = inverse_target_only(train_Y, scaler)\n",
    "\n",
    "# 反归一化测试集的预测结果和实际值\n",
    "test_predictions_inverse = inverse_target_only(test_predictions, scaler)\n",
    "test_actuals_inverse = inverse_target_only(test_Y, scaler)\n",
    "\n",
    "# 计算反归一化后的 RMSE 和 MAE\n",
    "train_rmse_inverse = np.sqrt(mean_squared_error(train_actuals_inverse, train_predictions_inverse))\n",
    "train_mae_inverse = mean_absolute_error(train_actuals_inverse, train_predictions_inverse)\n",
    "test_rmse_inverse = np.sqrt(mean_squared_error(test_actuals_inverse, test_predictions_inverse))\n",
    "test_mae_inverse = mean_absolute_error(test_actuals_inverse, test_predictions_inverse)\n",
    "\n",
    "# 打印反归一化后的性能指标\n",
    "print(f'Train RMSE (Inverse Scaled): {train_rmse_inverse:.4f}')\n",
    "print(f'Train MAE (Inverse Scaled): {train_mae_inverse:.4f}')\n",
    "print(f'Test RMSE (Inverse Scaled): {test_rmse_inverse:.4f}')\n",
    "print(f'Test MAE (Inverse Scaled): {test_mae_inverse:.4f}')\n",
    "\n",
    "# 绘制测试集预测与真实值对比（反归一化后）\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(test_predictions_inverse, label='Predicted - Test', color='blue')\n",
    "plt.plot(test_actuals_inverse, label='Actual - Test', color='orange')\n",
    "plt.title('Prediction vs Actual (Test Set) - Inverse Scaled')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 绘制测试集散点图（反归一化后）\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.scatter(test_predictions_inverse, test_actuals_inverse, label='Data Points', color='green', alpha=0.6)\n",
    "sns.regplot(x=test_predictions_inverse, y=test_actuals_inverse, scatter=False, label='Fit Line', color='red')\n",
    "plt.title('Fitted Curve: Predicted vs Actual (Test Set) - Inverse Scaled')\n",
    "plt.xlabel('Predicted Value (Inverse Scaled)')\n",
    "plt.ylabel('Actual Value (Inverse Scaled)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a8813f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9",
   "language": "python",
   "name": "py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
